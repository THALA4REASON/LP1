{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-AOItNrUEJAU"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer , WordNetLemmatizer\n",
        "import string"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_QPCUUZFARb",
        "outputId": "f52e12f5-9ab2-4894-af4e-ecfd906148d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filename = \"Conflation.txt\"\n",
        "with open(filename,'r',encoding='utf-8') as file:\n",
        "  text = file.read()\n",
        "\n",
        "print(text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "loLbe1lIFfLD",
        "outputId": "97d59ca9-5c2b-4684-8be7-5dfc7decd2b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Natural language processing (NLP) is a fascinating field of artificial intelligence that focuses on enabling computers to understand, interpret, and generate human language. \n",
            "Researchers and developers are constantly improving algorithms for tasks such as text classification, sentiment analysis, and machine translation. \n",
            "The goal of NLP is to make machines capable of understanding the context and meaning of language, not just recognizing words. \n",
            "\n",
            "For instance, stemming and lemmatization are common techniques used to reduce words to their base or root form. \n",
            "This process, known as conflation, helps in grouping related words together, improving the performance of text-based applications such as search engines and chatbots. \n",
            "\n",
            "As NLP continues to evolve, its applications are expanding into areas like healthcare, education, and customer support. \n",
            "With more data and better models, language technologies will become even more accurate and human-like in the near future.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = word_tokenize(text.lower())\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARiuwso-GGtC",
        "outputId": "f2a8705c-f571-4229-aa38-38882d570fcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['natural', 'language', 'processing', '(', 'nlp', ')', 'is', 'a', 'fascinating', 'field', 'of', 'artificial', 'intelligence', 'that', 'focuses', 'on', 'enabling', 'computers', 'to', 'understand', ',', 'interpret', ',', 'and', 'generate', 'human', 'language', '.', 'researchers', 'and', 'developers', 'are', 'constantly', 'improving', 'algorithms', 'for', 'tasks', 'such', 'as', 'text', 'classification', ',', 'sentiment', 'analysis', ',', 'and', 'machine', 'translation', '.', 'the', 'goal', 'of', 'nlp', 'is', 'to', 'make', 'machines', 'capable', 'of', 'understanding', 'the', 'context', 'and', 'meaning', 'of', 'language', ',', 'not', 'just', 'recognizing', 'words', '.', 'for', 'instance', ',', 'stemming', 'and', 'lemmatization', 'are', 'common', 'techniques', 'used', 'to', 'reduce', 'words', 'to', 'their', 'base', 'or', 'root', 'form', '.', 'this', 'process', ',', 'known', 'as', 'conflation', ',', 'helps', 'in', 'grouping', 'related', 'words', 'together', ',', 'improving', 'the', 'performance', 'of', 'text-based', 'applications', 'such', 'as', 'search', 'engines', 'and', 'chatbots', '.', 'as', 'nlp', 'continues', 'to', 'evolve', ',', 'its', 'applications', 'are', 'expanding', 'into', 'areas', 'like', 'healthcare', ',', 'education', ',', 'and', 'customer', 'support', '.', 'with', 'more', 'data', 'and', 'better', 'models', ',', 'language', 'technologies', 'will', 'become', 'even', 'more', 'accurate', 'and', 'human-like', 'in', 'the', 'near', 'future', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "tokens = [word for word in tokens if word.isalpha() and word not in stop_words]\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvvp_kTIGTJ5",
        "outputId": "5e1f5a1a-7db9-48c5-c257-619df2195d71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['natural', 'language', 'processing', 'nlp', 'fascinating', 'field', 'artificial', 'intelligence', 'focuses', 'enabling', 'computers', 'understand', 'interpret', 'generate', 'human', 'language', 'researchers', 'developers', 'constantly', 'improving', 'algorithms', 'tasks', 'text', 'classification', 'sentiment', 'analysis', 'machine', 'translation', 'goal', 'nlp', 'make', 'machines', 'capable', 'understanding', 'context', 'meaning', 'language', 'recognizing', 'words', 'instance', 'stemming', 'lemmatization', 'common', 'techniques', 'used', 'reduce', 'words', 'base', 'root', 'form', 'process', 'known', 'conflation', 'helps', 'grouping', 'related', 'words', 'together', 'improving', 'performance', 'applications', 'search', 'engines', 'chatbots', 'nlp', 'continues', 'evolve', 'applications', 'expanding', 'areas', 'like', 'healthcare', 'education', 'customer', 'support', 'data', 'better', 'models', 'language', 'technologies', 'become', 'even', 'accurate', 'near', 'future']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = PorterStemmer()\n",
        "stemmerd_word = [stemmer.stem(word) for word in tokens]\n",
        "print(\" \".join(stemmerd_word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q18P0uSbHGXg",
        "outputId": "1b862c6a-44c4-4c04-bfdf-016e3e88775c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "natur languag process nlp fascin field artifici intellig focus enabl comput understand interpret gener human languag research develop constantli improv algorithm task text classif sentiment analysi machin translat goal nlp make machin capabl understand context mean languag recogn word instanc stem lemmat common techniqu use reduc word base root form process known conflat help group relat word togeth improv perform applic search engin chatbot nlp continu evolv applic expand area like healthcar educ custom support data better model languag technolog becom even accur near futur\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmater = WordNetLemmatizer()\n",
        "lemmatized_words = [lemmater.lemmatize(word) for word in tokens]\n",
        "print(\" \".join(lemmatized_words))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CiJmlpgHR9R",
        "outputId": "798a6da6-18c3-42b0-ae5c-4b9da47917d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "natural language processing nlp fascinating field artificial intelligence focus enabling computer understand interpret generate human language researcher developer constantly improving algorithm task text classification sentiment analysis machine translation goal nlp make machine capable understanding context meaning language recognizing word instance stemming lemmatization common technique used reduce word base root form process known conflation help grouping related word together improving performance application search engine chatbots nlp continues evolve application expanding area like healthcare education customer support data better model language technology become even accurate near future\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "freq = Counter(stemmerd_word)\n",
        "for word, count in freq.most_common(10):\n",
        "  print(f\"{word} : count\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juLqw-QLID2x",
        "outputId": "6a10458f-9d51-48d2-b2ce-7a1ea4b91e65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "languag : count\n",
            "nlp : count\n",
            "word : count\n",
            "process : count\n",
            "understand : count\n",
            "improv : count\n",
            "machin : count\n",
            "applic : count\n",
            "natur : count\n",
            "fascin : count\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E4_mTN1KIjn3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}